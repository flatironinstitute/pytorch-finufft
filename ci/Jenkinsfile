pipeline {
  agent none
  options {
    disableConcurrentBuilds()
    buildDiscarder(logRotator(numToKeepStr: '8', daysToKeepStr: '20'))
    timeout(time: 1, unit: 'HOURS')
  }
  stages {
    stage('CUDA Tests') {
      agent {
         dockerfile {
            filename 'ci/docker/Dockerfile-cuda12.0'
            args '--gpus 1'
            label 'docker && v100'
         }
      }
      environment {
    HOME = "$WORKSPACE"
    LIBRARY_PATH = "$WORKSPACE/finufft/build"
    LD_LIBRARY_PATH = "$WORKSPACE/finufft/build"
      }
      steps {

    // TODO - reconsider install strategy once finufft/cufinufft 2.2 is released
  checkout scmGit(branches: [[name: '*/master']],
                  extensions: [cloneOption(noTags: true, reference: '', shallow: true),
                               [$class: 'RelativeTargetDirectory', relativeTargetDir: 'finufft'],
                               cleanAfterCheckout()],
                  userRemoteConfigs: [[url: 'https://github.com/flatironinstitute/finufft']])

    sh '''#!/bin/bash -ex
      nvidia-smi
    '''
    sh '''#!/bin/bash -ex
      echo $HOME
      ls
    '''
    sh '''#!/bin/bash -ex
        cd finufft
        # v100 cuda arch
        cuda_arch="70"

        cmake -B build . -DFINUFFT_USE_CUDA=ON \
                         -DFINUFFT_USE_CPU=OFF \
                         -DFINUFFT_BUILD_TESTS=OFF \
                         -DCMAKE_CUDA_ARCHITECTURES="$cuda_arch" \
                         -DBUILD_TESTING=ON
        cd build
        make -j4
    '''

    sh 'python3 -m venv $HOME'
    sh '''#!/bin/bash -ex
      source $HOME/bin/activate
      python3 -m pip install --upgrade pip
      # we could also move pytorch install inside docker
      python3 -m pip install "torch~=2.1.0" --index-url https://download.pytorch.org/whl/cu118
      python3 -m pip install finufft/python/cufinufft

      python3 -m pip install -e .[dev] # can make [dev,cuda] once cufinufft released?

      python3 -m pytest -k "cuda" tests/ --cov -v --error-for-skips --durations=20
    '''
      }
    }
  }
}
